{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Data_Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neighbors import LocalOutlierFactor as LOF\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data_folder = '/Feature Selection/Forest Prediction/'\n",
    "dataset = pd.read_csv(data_folder + 'data.csv')\n",
    "#dataset = dataset.iloc[0:200,:]\n",
    "# rem = ['Id','Soil_Type7','Soil_Type15']\n",
    "rem = ['Id']\n",
    "dataset.drop(rem,axis=1,inplace=True)\n",
    "\n",
    "r, c = dataset.shape\n",
    "array = dataset.values\n",
    "# X = array[:,0:(c-1)]\n",
    "# Y = array[:,(c-1)]\n",
    "X = dataset.iloc[:,0:(c-1)]\n",
    "Y = dataset.iloc[:,(c-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection \n",
    "X_train, X_val, Y_train, Y_val = model_selection .train_test_split(X, Y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Users/kunpengliu/anaconda2/envs/python36/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n  from numpy.core.umath_tests import inner1d\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_jobs=-1,n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(13608, 54)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Wilder_list = ['Wilderness_Area'+ str(i) for i in range(1,5)]\n",
    "soil_list = ['Soil_Type'+str(i) for i in range(1,41)]\n",
    "binary_list = Wilder_list+soil_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#a = dataset.iloc[:,0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#a_binary = a.loc[:,[i for i in a.columns if i in binary_list]]\n",
    "#a_conti = a.loc[:,[i for i in a.columns if i not in binary_list]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "N_feature = X_train.shape[1] # feature number\n",
    "N_sample = X_train.shape[0] # feature length,i.e., sample number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def Feature_GCN(X):\n",
    "    corr_matrix = X.corr().abs()\n",
    "    corr_matrix[np.isnan(corr_matrix)] = 0\n",
    "    corr_matrix_ = corr_matrix - np.eye(len(corr_matrix), k=0)\n",
    "    sum_vec = corr_matrix_.sum()\n",
    "    \n",
    "    for i in range(len(corr_matrix_)):\n",
    "    \n",
    "        corr_matrix_.iloc[:,i] = corr_matrix_.iloc[:,i]/sum_vec[i]\n",
    "        corr_matrix_.iloc[i,:] = corr_matrix_.iloc[i,:]/sum_vec[i]\n",
    "    W = corr_matrix_ + np.eye(len(corr_matrix), k=0)\n",
    "    Feature = np.mean(np.dot(X.values,W.values), axis=1)\n",
    "    \n",
    "    return Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([125.78215922, 125.16597397, 212.88705021, ..., 225.29321967,\n       154.72370093, 163.76352694])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 16
    }
   ],
   "source": [
    "Feature_GCN(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LR = 0.01\n",
    "EPSILON = 0.9\n",
    "GAMMA = 0.9\n",
    "TARGET_REPLACE_ITER = 100 # After how much time you refresh target network \n",
    "MEMORY_CAPACITY = 20 # The size of experience replay buffer \n",
    "EXPLORE_STEPS = 30 # How many exploration steps you'd like, should be larger than MEMORY_CAPACITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "N_ACTIONS = 2\n",
    "# N_STATES = env.observation_space.shape[0]\n",
    "N_STATES = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self,N_STATES,N_ACTIONS):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(N_STATES, 100)\n",
    "        self.fc1.weight.data.normal_(0,0.1) #initialization, set seed to ensure the same result\n",
    "        self.out = nn.Linear(100, N_ACTIONS)\n",
    "        self.out.weight.data.normal_(0,0.1) #initialization\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        action_value = self.out(x)\n",
    "        return action_value\n",
    "    \n",
    "    \n",
    "class DQN(object):\n",
    "    \n",
    "    def __init__(self,N_STATES,N_ACTIONS):\n",
    "        self.eval_net, self.target_net = Net(N_STATES,N_ACTIONS), Net(N_STATES,N_ACTIONS)\n",
    "        \n",
    "        self.learn_step_counter = 0\n",
    "        self.memory_counter = 0\n",
    "        self.memory = np.zeros((MEMORY_CAPACITY,N_STATES*2+2))\n",
    "        self.optimizer = torch.optim.Adam(self.eval_net.parameters(),lr=LR)\n",
    "        self.loss_func = nn.MSELoss()\n",
    "    def choose_action(self,x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        if np.random.uniform() < EPSILON:\n",
    "            action_value = self.eval_net.forward(x)\n",
    "            action = torch.max(action_value,1)[1].data.numpy()\n",
    "            action = action[0]\n",
    "        else:\n",
    "            action = np.random.randint(0,N_ACTIONS)\n",
    "        return action\n",
    "    def store_transition(self,s,a,r,s_):\n",
    "            transition = np.hstack((s,[a,r],s_))\n",
    "            index = self.memory_counter%MEMORY_CAPACITY # If full, restart from the beginning\n",
    "            self.memory[index,:] = transition\n",
    "            self.memory_counter +=1\n",
    "    def learn(self):\n",
    "        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:\n",
    "            self.target_net.load_state_dict(self.eval_net.state_dict())\n",
    "        self.learn_step_counter +=1\n",
    "            \n",
    "        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)\n",
    "        b_memory = self.memory[sample_index,:]\n",
    "        b_s = torch.FloatTensor(b_memory[:,:N_STATES])\n",
    "        b_a = torch.LongTensor(b_memory[:,N_STATES:N_STATES+1])\n",
    "        b_r = torch.FloatTensor(b_memory[:,N_STATES+1:N_STATES+2])\n",
    "        b_s_ = torch.FloatTensor(b_memory[:,-N_STATES:])\n",
    "        \n",
    "        q_eval = self.eval_net(b_s).gather(1,b_a)\n",
    "        q_next = self.target_net(b_s_).detach()\n",
    "        q_target = b_r + GAMMA*q_next.max(1)[0].view(BATCH_SIZE,1)\n",
    "        loss = self.loss_func(q_eval,q_target)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "CPU times: user 2.91 s, sys: 123 ms, total: 3.04 s\nWall time: 721 ms\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "action_list = np.random.randint(2,size=N_feature)\n",
    "\n",
    "i = 0\n",
    "while sum(action_list) < 2:\n",
    "    np.random.seed(i)\n",
    "    action_list = np.random.randint(2,size=N_feature)\n",
    "    i +=1\n",
    "\n",
    "X_selected = X_train.iloc[:,action_list==1]\n",
    "s = Feature_GCN(X_selected)\n",
    "\n",
    "model.fit(X_train.iloc[:,action_list==1],Y_train)\n",
    "accuracy = model.score(X_val.iloc[:,action_list==1], Y_val)\n",
    "ave_corr = X_val.corr().abs().sum().sum()/(X_val.shape[0]*X_val.shape[1])\n",
    "r_list = (accuracy- 10*ave_corr)/sum(action_list)*action_list\n",
    "\n",
    "action_list_p = action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.7096574721106297 0.7321428571428571\n",
      "0.701720964174122 0.7242063492063492\n",
      "0.722223609676767 0.7447089947089947\n",
      "0.7645516520048083 0.7870370370370371\n",
      "0.8194458318989892 0.841931216931217\n",
      "0.7215622340153913 0.7440476190476191\n",
      "0.8168003292534866 0.8392857142857143\n",
      "0.7175939800471377 0.7400793650793651\n",
      "0.7533082657614228 0.7757936507936508\n",
      "0.7440490065021631 0.7665343915343915\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "dqn_list = []\n",
    "for agent in range(N_feature):\n",
    "    dqn_list.append(DQN(N_STATES = N_STATES,N_ACTIONS = N_ACTIONS))\n",
    "# The element in the result list consists two parts, \n",
    "# i.e., accuracy and the action list (action 1 means selecting corresponding feature, 0 means deselection).\n",
    "result = [];\n",
    "    \n",
    "for i in range(EXPLORE_STEPS):    \n",
    "    action_list = np.zeros(N_feature)    \n",
    "    for agent, dqn in enumerate(dqn_list):\n",
    "         action_list[agent] = dqn.choose_action(s)\n",
    "            \n",
    "    while sum(action_list) < 2:\n",
    "        np.random.seed(i)\n",
    "        action_list = np.random.randint(2,size=N_feature)\n",
    "        i +=1\n",
    "            \n",
    "    X_selected = X_train.iloc[:,action_list==1]\n",
    "    s_ = Feature_GCN(X_selected)\n",
    "    \n",
    "    model.fit(X_train.iloc[:,action_list==1],Y_train)\n",
    "    accuracy = model.score(X_val.iloc[:,action_list==1], Y_val)\n",
    "    \n",
    "    ave_corr = X_val.corr().abs().sum().sum()/(X_val.shape[0]*X_val.shape[1])\n",
    "    \n",
    "    action_list_change = np.array([x or y for (x,y) in zip(action_list_p, action_list)])\n",
    "    r_list = (accuracy- 10*ave_corr)/sum(action_list_change)*action_list_change\n",
    "\n",
    "    for agent, dqn in enumerate(dqn_list):\n",
    "        dqn.store_transition(s, action_list[agent], r_list[agent], s_)\n",
    "\n",
    "    if dqn_list[0].memory_counter > MEMORY_CAPACITY:\n",
    "         for dqn in dqn_list:\n",
    "                dqn.learn()\n",
    "         print(sum(r_list),accuracy)\n",
    "    s = s_\n",
    "    action_list_p = action_list\n",
    "    result.append([accuracy, action_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The maximum accuracy is: 0.8578042328042328, the optimal selection for each feature is:[1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1.\n 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1.\n 0. 1. 1. 0. 1. 0.]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "max_accuracy = 0\n",
    "optimal_set = []\n",
    "for i in range(len(result)):\n",
    "    if result[i][0] >max_accuracy:\n",
    "        max_accuracy = result[i][0]\n",
    "        optimal_set = result[i][1]\n",
    "print(\"The maximum accuracy is: {}, the optimal selection for each feature is:{}\".format(max_accuracy, optimal_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}